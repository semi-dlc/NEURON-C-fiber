{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-25T15:07:00.381287Z",
     "start_time": "2026-02-25T15:06:59.728846Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dataProcessing import getData, getFilename, calculateLatency, calculateVelocity\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from stimulationProtocols import getCOVIDFullTime\n",
    "from plot import plotLatency, plotRecoveryCycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c26a3f902506521",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-25T15:07:00.397291Z",
     "start_time": "2026-02-25T15:07:00.381287Z"
    }
   },
   "outputs": [],
   "source": [
    "gPump = -0.0047891\n",
    "gNav17 = 0.10664\n",
    "gNav18 = 0.24271\n",
    "gNav19 = 9.4779e-05\n",
    "gKs = 0.0069733\n",
    "gKf = 0.012756\n",
    "gH = 0.0025377\n",
    "gKdr = 0.018002\n",
    "gKna = 0.00042\n",
    "vRest = -55\n",
    "\n",
    "param_orig = [\n",
    "    gPump,\n",
    "    gNav17,\n",
    "    gNav18,\n",
    "    gNav19,\n",
    "    gKs,\n",
    "    gKf,\n",
    "    gH,\n",
    "    gKdr,\n",
    "    gKna\n",
    "]\n",
    "# -0.5 too less. Might need to increase to finer ones. Also faster is probably higher conductance, intuitively?? But for all channels?\n",
    "changes = [-0.2, -0.18, -0.15, -0.1, -0.05, -0.03, 0.0, 0.03, 0.05, 0.1, 0.15, 0.18, 0.2, 0.25, 0.5]\n",
    "param_names = ['gPump', 'gNav17', 'gNav18', 'gNav19', 'gKs', 'gKf', 'gH', 'gKdr', 'gKna']\n",
    "params = {}\n",
    "spikes = {}\n",
    "\n",
    "for name in param_names:\n",
    "    params[name] = {}\n",
    "    spikes[name] = {}\n",
    "for i, x in enumerate(param_orig):\n",
    "    for dg in changes:\n",
    "        param_new = param_orig.copy()\n",
    "        param_new[i] = param_orig[i] * (1 + dg) # scale 1 parameter\n",
    "\n",
    "        params[param_names[i]][dg] = param_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73153cea1a09e9e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-25T15:07:00.558542Z",
     "start_time": "2026-02-25T15:07:00.542735Z"
    }
   },
   "outputs": [],
   "source": [
    "protocol = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbefe67e0ab1e804",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-25T15:07:00.812812Z",
     "start_time": "2026-02-25T15:07:00.558542Z"
    }
   },
   "outputs": [],
   "source": [
    "for name in param_names:\n",
    "    for j, dg in enumerate(changes):\n",
    "        param = params[name][dg]\n",
    "        spike = getData(prot=protocol, filetype=\"spikes\", scalingFactor=0.1, gPump=param[0], gNav17=param[1], gNav18=param[2], gNav19=param[3], gKs=param[4], gKf=param[5], gH=param[6], gKdr=param[7], gKna=param[8])\n",
    "        spikes[name][dg] = spike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c69b5e09b7193f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-25T15:07:00.849444Z",
     "start_time": "2026-02-25T15:07:00.828698Z"
    }
   },
   "outputs": [],
   "source": [
    "stims = getData(prot=protocol, filetype=\"stim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9940197440c1a442",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-25T15:07:00.870675Z",
     "start_time": "2026-02-25T15:07:00.865267Z"
    }
   },
   "outputs": [],
   "source": [
    "#plotRecoveryCycle(spikes, stims)\n",
    "print(len(spikes),len(stims))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ee068f82a0ca63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-25T15:07:01.387412Z",
     "start_time": "2026-02-25T15:07:00.888703Z"
    }
   },
   "outputs": [],
   "source": [
    "latencies = np.zeros((len(param_orig),len(changes), len(stims)))\n",
    "for i, name in enumerate(param_names):\n",
    "    for j, dg in enumerate(changes):\n",
    "        latencies[i][j] = calculateLatency(spikes[name][dg], stims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2fe44b9644679a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-25T15:07:01.908988Z",
     "start_time": "2026-02-25T15:07:01.408421Z"
    }
   },
   "outputs": [],
   "source": [
    "initial_velocities = np.zeros((len(param_orig),len(changes)))\n",
    "for i, name in enumerate(param_names):\n",
    "    for j, dg in enumerate(changes):\n",
    "        v = calculateVelocity(spikes[name][dg], stims)\n",
    "        initial_velocities[i][j] = v[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe66bb1c7ec399b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-25T15:07:01.986495Z",
     "start_time": "2026-02-25T15:07:01.955118Z"
    }
   },
   "outputs": [],
   "source": [
    "Slow025HzStart = 1\n",
    "Slow025HzEnd = 90\n",
    "Fast2HzStart = 90 # 90 stimulations at 0.25 Hz initially\n",
    "Fast2HzEnd = 450 # 360 stimulations at 2 Hz\n",
    "Fast2HzPost30S = Fast2HzEnd + 8 # 32 s after reducing the stimulation frequency from 2 Hz to 0.25 Hz again\n",
    "# last one is the end of simulation\n",
    "SimulationEnd = latencies.shape[2] - 1\n",
    "points = [Slow025HzStart, Slow025HzEnd, Fast2HzStart, Fast2HzEnd, Fast2HzPost30S, SimulationEnd]\n",
    "points_name = [\"InitialVelocity\", \"Slow025HzStart\", \"Slow025HzEnd\", \"Fast2HzStart\", \"Fast2HzEnd\", \"Fast2HzPost30S\", \"SimulationEnd\"]\n",
    "slowing_name = [points_name[0], points_name[1]+\"-\"+points_name[2], points_name[3]+\"-\"+points_name[4], points_name[5], \"TimeTo50Percent\"]\n",
    "\n",
    "latencies_rel = np.zeros((len(param_orig),len(changes), 6))\n",
    "slowing_abs = np.zeros((len(param_orig),len(changes), 5)) # Slowing 0 to 0.25, 0.25 to 2, recovery at 30 s, Time to 50% recovery\n",
    "\n",
    "# as dicts\n",
    "latency_dict = {}\n",
    "slowing_dict = {}\n",
    "\n",
    "for i, name in enumerate(param_names):\n",
    "    latency_dict[name] = {}\n",
    "    slowing_dict[name] = {}\n",
    "    for j, dg in enumerate(changes):\n",
    "        latency_dict[name][dg] = {}\n",
    "        slowing_dict[name][dg] = {}\n",
    "        for k, (point, point_name) in enumerate(zip(points, points_name)):\n",
    "            latencies_rel[i][j][k] = latencies[i][j][point]\n",
    "            latency_dict[name][dg][point_name] = latencies[i][j][point]\n",
    "        # Initial velocity\n",
    "        slowing_abs[i][j][0] = initial_velocities[i][j]\n",
    "        slowing_dict[name][dg][slowing_name[0]] = slowing_abs[i][j][0]\n",
    "\n",
    "        # Slowing 0 to 0.25\n",
    "        slowing_abs[i][j][1] = (latencies[i][j][Slow025HzEnd] - latencies[i][j][Slow025HzStart]) / latencies[i][j][Slow025HzStart] - 1\n",
    "        slowing_dict[name][dg][slowing_name[1]] = slowing_abs[i][j][1]\n",
    "\n",
    "        # Slowing 0.25 to 2\n",
    "        slowing_abs[i][j][2] = (latencies[i][j][Fast2HzEnd] - latencies[i][j][Fast2HzStart]) / latencies[i][j][Fast2HzStart] - 1\n",
    "        slowing_dict[name][dg][slowing_name[2]] = slowing_abs[i][j][2]\n",
    "\n",
    "        # recovery at 30 s (latency at 30 s after 2 Hz stimulation compared to latency before 2 Hz stimulation)\n",
    "        slowing_abs[i][j][3] = (latencies[i][j][Fast2HzPost30S] - latencies[i][j][Fast2HzStart]) / latencies[i][j][Fast2HzStart]\n",
    "        slowing_dict[name][dg][slowing_name[3]] = slowing_abs[i][j][3]\n",
    "\n",
    "        recovery_50_percent_threshold = (latencies[i][j][Fast2HzStart] + latencies[i][j][Fast2HzEnd]) / 2\n",
    "        # time to 50 % recovery\n",
    "        for n in np.arange(Fast2HzEnd, SimulationEnd):\n",
    "            # if the latency at number t-th spike is lower than the 50 % recovery threshold\n",
    "            if latencies[i][j][n] < recovery_50_percent_threshold:\n",
    "                # use the time as the time until 50 % recovery\n",
    "                slowing_abs[i][j][4] = getCOVIDFullTime(n) - getCOVIDFullTime(Fast2HzStart) # can be made more precise with linear interpolation\n",
    "                slowing_dict[name][dg][slowing_name[4]] = slowing_abs[i][j][4]\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40edb102bbc91c42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-25T15:07:02.002376Z",
     "start_time": "2026-02-25T15:07:01.986495Z"
    }
   },
   "outputs": [],
   "source": [
    "getCOVIDFullTime(90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a633442e1c8d252",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-25T15:07:04.629407Z",
     "start_time": "2026-02-25T15:07:02.034226Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot raw latencies\n",
    "fig, axes = plt.subplots(len(param_names), 1, figsize=(6, 6*len(param_names)))\n",
    "for i, name_g in enumerate(param_names):\n",
    "    ax = axes[i]\n",
    "    latency = latencies[i]\n",
    "    for j, latency in enumerate(latency):\n",
    "        ax.plot(latency, alpha=0.8, label=f\"{name_g} {changes[j]*100:.2f}%\")\n",
    "    ax.set_xlabel(\"Action potential\")\n",
    "\n",
    "    ax.set_ylabel(\"Latency (ms)\")\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "    ax.set_title(f\"Latency when varying {name_g}\")\n",
    "plt.savefig(f\"Results/raw_latencies_plot.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47853de7ec0793c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-25T15:11:16.501225Z",
     "start_time": "2026-02-25T15:11:11.057846Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot slowings\n",
    "fig, axes = plt.subplots(len(param_names), slowing_abs.shape[-1], figsize=(35, 5*len(param_names)))\n",
    "# Different parameters\n",
    "for i, name_g in enumerate(param_names):\n",
    "    slowings = slowing_abs[i]\n",
    "    # Different changes\n",
    "    for j in np.arange(slowings.shape[1]):\n",
    "        axes[i,j].plot(changes, slowings[:, j], alpha=0.8, label=f\"{name_g} \")\n",
    "        #axes[i,j].set_xticks(changes[::3])\n",
    "        axes[i,j].set_xlabel(f\"Change {name_g}\")\n",
    "        axes[i,0].set_ylabel(\"Velocity [mm/ms]\") # IS THIS UNIT MM/MS CORRECT?? see unit of calculateVelocity\n",
    "        for k in (1, 2, 3):\n",
    "            axes[i,k].set_ylabel(\"Change in latency [%]\")\n",
    "        axes[i,4].set_ylabel(\"Time to 50% recovery [us]\")\n",
    "        axes[i,j].grid(True)\n",
    "        axes[i,j].legend()\n",
    "        axes[i, j].set_title(f\"{slowing_name[j]}\")\n",
    "plt.savefig(f\"Results/relative_slowings_plot.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d29d208c0173c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-25T15:09:56.368285Z",
     "start_time": "2026-02-25T15:09:50.694831Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot deviations to \"normal\" model\n",
    "i_normal = 6 # where changes = 0\n",
    "\n",
    "# Normalize slowings to slowing with zero changes to original parameters\n",
    "normal_value = slowing_abs[:, i_normal, :]\n",
    "slowing_rel = slowing_abs / normal_value[:, np.newaxis, :] # divide/normalize by respective value of original parameter that was not changed\n",
    "\n",
    "# Plot slowings\n",
    "fig, axes = plt.subplots(len(param_names), slowing_rel.shape[-1], figsize=(35, 5*len(param_names)))\n",
    "# Different parameters\n",
    "for i, name_g in enumerate(param_names):\n",
    "    slowings_norm = slowing_rel[i]\n",
    "\n",
    "    # Different changes\n",
    "    for j in np.arange(slowings_norm.shape[1]):\n",
    "        axes[i,j].plot(changes, slowings_norm[:, j], alpha=0.8, label=f\"{name_g} \")\n",
    "        #axes[i,j].set_xticks(changes[::3])\n",
    "        axes[i,j].set_xlabel(f\"Change {name_g}\")\n",
    "        axes[i,0].set_ylabel(\"Relative change in velocity\")\n",
    "        for k in (1, 2, 3):\n",
    "            axes[i,k].set_ylabel(\"Relative change in latency\")\n",
    "        axes[i,4].set_ylabel(\"Relative Time to 50% recovery\")\n",
    "        axes[i,j].grid(True)\n",
    "        axes[i,j].legend()\n",
    "        axes[i, j].set_title(f\"{slowing_name[j]}\")\n",
    "\n",
    "plt.suptitle(f\"Changes, relative to original model\")\n",
    "plt.savefig(f\"Results/relative_slowings_normalized_plot.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d20c2d024312883",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-25T15:07:13.272019Z",
     "start_time": "2026-02-25T15:07:13.255937Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ribeiro et al: Peripheral C fibers in long COVID, page 9, mean values of Type 1B fibres for COVID and healthy patients\n",
    "# Data does not match!\n",
    "experiment_values = {}\n",
    "experiment_values_labels = [\"CV\", \"0to025\", \"025to2\", \"30sRecovery\", \"50%RecoveryTime\"]\n",
    "experiment_values_covid = np.array([0.52, 5.52, 31.8, 31.6, 62.2])\n",
    "experiment_values_healthy = np.array([0.43, 4.09, 36, 19.7, 96.2])\n",
    "experiment_factors = experiment_values_covid/experiment_values_healthy\n",
    "for l, c, h, f in zip(experiment_values_labels, experiment_values_covid, experiment_values_healthy, experiment_factors):\n",
    "    experiment_values[l] = {}\n",
    "    experiment_values[l][\"Covid\"] = c\n",
    "    experiment_values[l][\"Healthy\"] = h\n",
    "    experiment_values[l][\"Factor\"] = f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf477375cafffbe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-25T15:07:13.335776Z",
     "start_time": "2026-02-25T15:07:13.320080Z"
    }
   },
   "outputs": [],
   "source": [
    "# Optimisation task: Find param that slowing_rel \\approx experiment_factors\n",
    "# We can treat experiment_factors as the product of slowing_rel\n",
    "# 8 channels, 4 values -> should be possible\n",
    "# underconstrained problem -> multiple solutions\n",
    "# LLM says: add regularization constraints (e.g. least deviation from original parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f0e4f4aa770c64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-25T15:07:13.399429Z",
     "start_time": "2026-02-25T15:07:13.383569Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
